{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f08778b",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d200d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data shape before merge: (17544, 3)\n",
      "Load data shape after merge: (17544, 4)\n",
      "\n",
      "Missing temperature values after merge: 9\n",
      "\n",
      "Rows with missing temperature values:\n",
      "Total missing values: 9\n",
      "\n",
      "First 10 rows with missing temperature values:\n",
      "                 datetime   Load\n",
      "6800  2023-10-11 08:00:00   9888\n",
      "6801  2023-10-11 09:00:00   9850\n",
      "6802  2023-10-11 10:00:00   9679\n",
      "6803  2023-10-11 11:00:00   9544\n",
      "6805  2023-10-11 13:00:00   9245\n",
      "6943  2023-10-17 07:00:00  10537\n",
      "6944  2023-10-17 08:00:00  10341\n",
      "14983 2024-09-16 07:00:00   9398\n",
      "14984 2024-09-16 08:00:00   9359\n",
      "\n",
      "Missing values by month:\n",
      "datetime\n",
      "9     2\n",
      "10    7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values by hour of day:\n",
      "datetime\n",
      "7     2\n",
      "8     3\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "13    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Time differences between consecutive missing values (first 10):\n",
      "6800                  NaT\n",
      "6801      0 days 01:00:00\n",
      "6802      0 days 01:00:00\n",
      "6803      0 days 01:00:00\n",
      "6805      0 days 02:00:00\n",
      "6943      5 days 18:00:00\n",
      "6944      0 days 01:00:00\n",
      "14983   334 days 23:00:00\n",
      "14984     0 days 01:00:00\n",
      "Name: datetime, dtype: timedelta64[ns]\n",
      "Most common time difference between missing values: 0 days 01:00:00\n",
      "\n",
      "Remaining missing values after interpolation: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakfa\\AppData\\Local\\Temp\\ipykernel_13584\\834141821.py:92: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  load_df_temp['Temperature'] = load_df_temp['Temperature'].fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataframe sample:\n",
      "             datetime  entso-e_forecast  Load  Temperature  Month  \\\n",
      "0 2023-01-01 00:00:00              8897  8943          3.6      1   \n",
      "1 2023-01-01 01:00:00              8836  8929          3.0      1   \n",
      "2 2023-01-01 02:00:00              8779  8887          2.6      1   \n",
      "3 2023-01-01 03:00:00              8806  8859          2.4      1   \n",
      "4 2023-01-01 04:00:00              8958  8880          2.0      1   \n",
      "\n",
      "   Day_of_week  Hour_of_day  Holidays  DST  \n",
      "0            6            0         0    0  \n",
      "1            6            1         0    0  \n",
      "2            6            2         0    0  \n",
      "3            6            3         0    0  \n",
      "4            6            4         0    0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>entso-e_forecast</th>\n",
       "      <th>Load</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Hour_of_day</th>\n",
       "      <th>Holidays</th>\n",
       "      <th>DST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>8897</td>\n",
       "      <td>8943</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>8836</td>\n",
       "      <td>8929</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>8779</td>\n",
       "      <td>8887</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>8806</td>\n",
       "      <td>8859</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>8958</td>\n",
       "      <td>8880</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17539</th>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "      <td>10929</td>\n",
       "      <td>11092</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17540</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "      <td>10568</td>\n",
       "      <td>10798</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17541</th>\n",
       "      <td>2024-12-31 21:00:00</td>\n",
       "      <td>10272</td>\n",
       "      <td>10531</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17542</th>\n",
       "      <td>2024-12-31 22:00:00</td>\n",
       "      <td>9981</td>\n",
       "      <td>10165</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17543</th>\n",
       "      <td>2024-12-31 23:00:00</td>\n",
       "      <td>9791</td>\n",
       "      <td>9848</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17544 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  entso-e_forecast   Load  Temperature  Month  \\\n",
       "0     2023-01-01 00:00:00              8897   8943          3.6      1   \n",
       "1     2023-01-01 01:00:00              8836   8929          3.0      1   \n",
       "2     2023-01-01 02:00:00              8779   8887          2.6      1   \n",
       "3     2023-01-01 03:00:00              8806   8859          2.4      1   \n",
       "4     2023-01-01 04:00:00              8958   8880          2.0      1   \n",
       "...                   ...               ...    ...          ...    ...   \n",
       "17539 2024-12-31 19:00:00             10929  11092         -2.1     12   \n",
       "17540 2024-12-31 20:00:00             10568  10798         -1.8     12   \n",
       "17541 2024-12-31 21:00:00             10272  10531         -3.0     12   \n",
       "17542 2024-12-31 22:00:00              9981  10165         -2.7     12   \n",
       "17543 2024-12-31 23:00:00              9791   9848         -1.4     12   \n",
       "\n",
       "       Day_of_week  Hour_of_day  Holidays  DST  \n",
       "0                6            0         0    0  \n",
       "1                6            1         0    0  \n",
       "2                6            2         0    0  \n",
       "3                6            3         0    0  \n",
       "4                6            4         0    0  \n",
       "...            ...          ...       ...  ...  \n",
       "17539            1           19         1    0  \n",
       "17540            1           20         1    0  \n",
       "17541            1           21         1    0  \n",
       "17542            1           22         1    0  \n",
       "17543            1           23         1    0  \n",
       "\n",
       "[17544 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pytz\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from darts import TimeSeries\n",
    "from darts.metrics import mape, rmse, mae\n",
    "\n",
    "\n",
    "# Create a DataFrame from Load source\n",
    "load2023 = pd.read_csv(\"Load_Data/Total Load - Day Ahead _ Actual_2023.csv\", delimiter=\",\")\n",
    "load2024 = pd.read_csv(\"Load_Data/Total Load - Day Ahead _ Actual_2024.csv\", delimiter=\",\")\n",
    "load_df = pd.concat([load2023, load2024], ignore_index=True)\n",
    "\n",
    "# Read temperature data (downlaoded from SMHI)\n",
    "weather_data = pd.read_csv(\"Temperature Data/smhi-opendata_1_98230_202301_202412.csv\", delimiter=\";\", skiprows=9)\n",
    "\n",
    "# Process load data by changing column name\n",
    "load_df['Time (UTC)'] = load_df['Time (UTC)'].str.split(' - ').str[0]\n",
    "load_df = load_df.rename(columns={'Time (UTC)': 'completetime', 'Actual Total Load [MW] - BZN|SE3': 'Load'})\n",
    "load_df['datetime'] = pd.to_datetime(load_df['completetime'], format='%d.%m.%Y %H:%M')\n",
    "load_df = load_df.drop(['completetime'], axis=1)\n",
    "\n",
    "# Create datetime in weather_data\n",
    "date_col = 'Datum'  \n",
    "time_col = 'Tid (UTC)'  \n",
    "\n",
    "# Create datetime column in weather_data by combining date and time\n",
    "weather_data['datetime'] = pd.to_datetime(\n",
    "    weather_data[date_col].astype(str) + ' ' + weather_data[time_col].astype(str)\n",
    ")\n",
    "\n",
    "# Create a temporary dataframe with just datetime and temperature\n",
    "temp_df = weather_data[['datetime', 'Lufttemperatur']].copy()\n",
    "temp_df.rename(columns={'Lufttemperatur': 'Temperature'}, inplace=True)\n",
    "\n",
    "\n",
    "# Remove any duplicates in temperature data (checking by datetime)\n",
    "if temp_df['datetime'].duplicated().any():\n",
    "    print(f\"Found {temp_df['datetime'].duplicated().sum()} duplicate timestamps in temperature data Stockholm\")\n",
    "    temp_df = temp_df.drop_duplicates(subset=['datetime'])\n",
    "\n",
    "# Merge the dataframes based on datetime\n",
    "print(f\"Load data shape before merge: {load_df.shape}\")\n",
    "load_df = load_df.merge(temp_df, on='datetime', how='left')\n",
    "print(f\"Load data shape after merge: {load_df.shape}\")\n",
    "\n",
    "# Check for missing temperature values and identify where they are\n",
    "missing_temp = load_df['Temperature'].isna().sum()\n",
    "print(f\"\\nMissing temperature values after merge: {missing_temp}\")\n",
    "\n",
    "# Check the temprature missing data and doing interpolation\n",
    "if missing_temp > 0:\n",
    "    # Find rows with missing temperature values\n",
    "    missing_rows = load_df[load_df['Temperature'].isna()]\n",
    "    \n",
    "    # Display information about the missing data\n",
    "    print(\"\\nRows with missing temperature values:\")\n",
    "    print(f\"Total missing values: {len(missing_rows)}\")\n",
    "    \n",
    "    # Show the first few rows with missing values\n",
    "    print(\"\\nFirst 10 rows with missing temperature values:\")\n",
    "    print(missing_rows[['datetime', 'Load']].head(10))\n",
    "    \n",
    "    # Show the distribution of missing values by month and hour\n",
    "    print(\"\\nMissing values by month:\")\n",
    "    print(missing_rows['datetime'].dt.month.value_counts().sort_index())\n",
    "    \n",
    "    print(\"\\nMissing values by hour of day:\")\n",
    "    print(missing_rows['datetime'].dt.hour.value_counts().sort_index())\n",
    "    \n",
    "    # Check if missing values are consecutive\n",
    "    missing_rows_sorted = missing_rows.sort_values('datetime')\n",
    "    time_diff = missing_rows_sorted['datetime'].diff()\n",
    "    \n",
    "    print(\"\\nTime differences between consecutive missing values (first 10):\")\n",
    "    print(time_diff.head(10))\n",
    "    \n",
    "    # Identify gaps in temperature data\n",
    "    common_diff = time_diff.mode()[0]\n",
    "    print(f\"Most common time difference between missing values: {common_diff}\")\n",
    "    \n",
    "    # Set datetime as index for time-based interpolation\n",
    "    load_df_temp = load_df.set_index('datetime')\n",
    "    \n",
    "    # Perform interpolation\n",
    "    load_df_temp['Temperature'] = load_df_temp['Temperature'].interpolate(method='time')\n",
    "    \n",
    "    # Handle any remaining missing values\n",
    "    load_df_temp['Temperature'] = load_df_temp['Temperature'].fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # Reset index\n",
    "    load_df = load_df_temp.reset_index()\n",
    "    \n",
    "    print(f\"\\nRemaining missing values after interpolation: {load_df['Temperature'].isna().sum()}\")\n",
    "\n",
    "# Adding day type (Month, Week and hour of the day)\n",
    "load_df['Month'] = load_df['datetime'].dt.month\n",
    "load_df['Day_of_week'] = load_df['datetime'].dt.dayofweek\n",
    "load_df['Hour_of_day'] = load_df['datetime'].dt.hour\n",
    "\n",
    "# change column name\n",
    "load_df['entso-e_forecast']=load_df['Day-ahead Total Load Forecast [MW] - BZN|SE3']\n",
    "\n",
    "# Adding Holidays \n",
    "Sweden_holidays = holidays.CountryHoliday('SE')\n",
    "load_df['Holidays'] = [int((date in Sweden_holidays) and date.weekday() != 6) for date in load_df.datetime]\n",
    "\n",
    "# Create Daylight Saving Column covariates\n",
    "# Define Sweden timezone\n",
    "sweden_tz = pytz.timezone('Europe/Stockholm')\n",
    "\n",
    "def is_dst_sweden(naive_dt):\n",
    "    try:\n",
    "        # First, assume the naive datetime is in UTC\n",
    "        utc_dt = pd.Timestamp(naive_dt).tz_localize('UTC')\n",
    "        # Then convert UTC time to Sweden time\n",
    "        sweden_time = utc_dt.astimezone(sweden_tz)\n",
    "        # Return 1 if DST is active, 0 if not\n",
    "        return int(sweden_time.dst() != pd.Timedelta(0))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {naive_dt}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the function to get DST status (1 or 0)\n",
    "load_df['DST'] = load_df['datetime'].apply(is_dst_sweden)\n",
    "\n",
    "# Reorder columns\n",
    "load_df = load_df[['datetime', 'entso-e_forecast','Load', 'Temperature', 'Month','Day_of_week', 'Hour_of_day', 'Holidays','DST']]\n",
    "\n",
    "# Display a sample of the final dataframe\n",
    "print(\"\\nFinal dataframe sample:\")\n",
    "print(load_df.head())\n",
    "\n",
    "# Convert the panda data frame into DART dataseries\n",
    "Load = TimeSeries.from_dataframe(\n",
    "    df=load_df,\n",
    "    time_col=\"datetime\",\n",
    "    value_cols=[\"Load\"]\n",
    ")\n",
    "\n",
    "Temp = TimeSeries.from_dataframe(\n",
    "    df=load_df,\n",
    "    time_col=\"datetime\",\n",
    "    value_cols=[\"Temperature\"]\n",
    ")\n",
    "\n",
    "Holidays = TimeSeries.from_dataframe(\n",
    "    df=load_df,\n",
    "    time_col=\"datetime\",\n",
    "    value_cols=[\"Holidays\"]\n",
    ")\n",
    "\n",
    "load_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
